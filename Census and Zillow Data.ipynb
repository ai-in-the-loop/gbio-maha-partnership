{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census and Zillow Data Cleaning\n",
    "After talking with Tom and John from MAHA and GBIO, one ask that came to us was to see if there were any ways we could use data to get insight into the \"NIMBY vs. YIMBY\" debate currently happening in housing justice communities across the U.S.\n",
    "\n",
    "When we started talking about what data could provide value into this conversation, we thought about rental data, and Zillow came up as a possible source of data. We also thought the census would have useful data to do this research too. Both of these sources of data turned out to be useful as a starting point for the conversation.\n",
    "\n",
    "From the census, we were able to find data that contained information on the number of authorized construction permits for private residential units, per year, per metro area (as defined by the census). This was retrievable via the [FactFinder](https://factfinder.census.gov/faces/nav/jsf/pages/index.xhtml) area of their website. There was data going as far back as the early 2000s, but all of the data collected after 2014 was collected differently – so I started by just looking at data for 2014-2016.\n",
    "\n",
    "Zillow also has a set of [research data sets](https://www.zillow.com/research/data/). From this, I was able to find median rent prices, per year, per metro area (as defined by Zillow). The Zillow data had median rent prices broken down as far as neighborhoods within metro areas (i.e. Queens within New York), so I had to consolidate those neighborhoods first, and grab the average median rent per metro area.\n",
    "\n",
    "You can see both of these data sets in our google drive.\n",
    "\n",
    "With both of these data sets, it was a matter of cleaning and combining the data, trying as best as possible to match the data by similarly names metro regions. The formats for each metro region were different, but for the most part, Zillow would use the central city of a metro area to refer to the whole region, while the census would use a more detailed name (i.e. \"Lost Angeles\" in Zillow, and \"Los Angeles-Aneheim\" in the census). So, in order to match them, I basically searched each census metro area's name to see if it contained the name of the Zillow metro area or not – this means asking through code to see if the words \"Los Angeles\" appear anywhere in the phrases \"New York-Newark\", or in \"Los Angeles-Aneheim\", and putting the data from one data set alongside the other if they do.\n",
    "\n",
    "Here's some of the code I used to get the data from a `.csv` format, and combine it into one data set, and export it as its own `.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# first, consolidate the Zillow median rent data on 2BR houses into one file of median rent per metro area\n",
    "try:\n",
    "    with open('2BR-median-rent-data.csv', 'rU') as readfile: # Zillow median rent data 2BR, by neighborhood\n",
    "        reader = csv.DictReader(readfile, dialect=csv.excel) # Library for parsing csv files into python\n",
    "        for row in reader:\n",
    "            if row['Metro Area 3BR'] != '': # I mislabeled the data when I pulled it down by accident\n",
    "                key = '%s-%s' % (row['Metro Area 3BR'].lower(), row['State 3BR'].lower())\n",
    "                if two_br_data.get(key) is None:\n",
    "                    two_br_data[key] = {'state': row['State 3BR'].lower(),'2014': [],'2015': [],'2016': []}\n",
    "                if row['3BR 2014 AVG Median Rent'] != '':\n",
    "                    two_br_data[key]['2014'].append(row['3BR 2014 AVG Median Rent'])\n",
    "                if row['3BR 2015 AVG Median Rent'] != '':\n",
    "                    two_br_data[key]['2015'].append(row['3BR 2015 AVG Median Rent'])\n",
    "                if row['3BR 2016 AVG Median Rent'] != '':\n",
    "                    two_br_data[key]['2016'].append(row['3BR 2016 AVG Median Rent'])\n",
    "except OSError:\n",
    "    print (\"error getting input file\")\n",
    "finally:\n",
    "    readfile.close()\n",
    "\n",
    "with open('2BR-median-rent-data-consolidated.csv', 'w') as writefile: # The file to create, with median rent prices per metro area\n",
    "    writer = csv.DictWriter(writefile, fieldnames=['State', 'Metro', '2014 AVG Median Rent', '2015 AVG Median Rent', '2016 AVG Median Rent'])\n",
    "    writer.writeheader()\n",
    "    for key in two_br_data.keys():\n",
    "        median_2014 = ''\n",
    "        median_2015 = ''\n",
    "        median_2016 = ''\n",
    "        if len(two_br_data[key]['2014']) > 0: # create average median rent prices/year for each metro area\n",
    "            median_2014 = functools.reduce(lambda x, y: x + float(y), two_br_data[key]['2014'], 0) / len(two_br_data[key]['2014'])\n",
    "        if len(two_br_data[key]['2015']) > 0:\n",
    "            median_2015 = functools.reduce(lambda x, y: x + float(y), two_br_data[key]['2015'], 0) / len(two_br_data[key]['2015'])\n",
    "        if len(two_br_data[key]['2016']) > 0:\n",
    "            median_2016 = functools.reduce(lambda x, y: x + float(y), two_br_data[key]['2016'], 0) / len(two_br_data[key]['2016'])\n",
    "        new_row = {'State': two_br_data[key]['state'], 'Metro': key.split('-')[0], '2014 AVG Median Rent': median_2014, '2015 AVG Median Rent': median_2015, '2016 AVG Median Rent': median_2016}\n",
    "        writer.writerow(new_row)\n",
    "\n",
    "# consolidate data in the same way, but for 3BR houses on Zillow\n",
    "try:\n",
    "    with open('3BR-median-rent-data.csv', 'rU') as readfile:\n",
    "        reader = csv.DictReader(readfile, dialect=csv.excel)\n",
    "        for row in reader:\n",
    "            if row['Metro'] != '':\n",
    "                key = '%s-%s' % (row['Metro'].lower(), row['State'].lower())\n",
    "                if three_br_data.get(key) is None:\n",
    "                    three_br_data[key] = {'state': row['State'].lower(),'2014': [],'2015': [],'2016': []}\n",
    "                if row['2014-average'] != '':\n",
    "                    three_br_data[key]['2014'].append(row['2014-average'])\n",
    "                if row['2015-average'] != '':\n",
    "                    three_br_data[key]['2015'].append(row['2015-average'])\n",
    "                if row['2016-average'] != '':\n",
    "                    three_br_data[key]['2016'].append(row['2016-average'])\n",
    "except OSError:\n",
    "    print (\"error getting input file\")\n",
    "finally:\n",
    "    readfile.close()\n",
    "\n",
    "with open('3BR-median-rent-data-consolidated.csv', 'w') as writefile:\n",
    "    writer = csv.DictWriter(writefile, fieldnames=['State', 'Metro', '2014 AVG Median Rent', '2015 AVG Median Rent', '2016 AVG Median Rent'])\n",
    "    writer.writeheader()\n",
    "    for key in three_br_data.keys():\n",
    "        median_2014 = ''\n",
    "        median_2015 = ''\n",
    "        median_2016 = ''\n",
    "        if len(three_br_data[key]['2014']) > 0:\n",
    "            median_2014 = functools.reduce(lambda x, y: x + float(y), three_br_data[key]['2014'], 0) / len(three_br_data[key]['2014'])\n",
    "        if len(three_br_data[key]['2015']) > 0:\n",
    "            median_2015 = functools.reduce(lambda x, y: x + float(y), three_br_data[key]['2015'], 0) / len(three_br_data[key]['2015'])\n",
    "        if len(three_br_data[key]['2016']) > 0:\n",
    "            median_2016 = functools.reduce(lambda x, y: x + float(y), three_br_data[key]['2016'], 0) / len(three_br_data[key]['2016'])\n",
    "        new_row = {'State': three_br_data[key]['state'], 'Metro': key.split('-')[0], '2014 AVG Median Rent': median_2014, '2015 AVG Median Rent': median_2015, '2016 AVG Median Rent': median_2016}\n",
    "        writer.writerow(new_row)\n",
    "\n",
    "\n",
    "# Create a dictionary in python into which to put the consolidated data\n",
    "data_together = {}\n",
    "\n",
    "# First, get the data for the 3BR houses from the file created to hold average median rent prices by area\n",
    "try:\n",
    "    with open('3BR-median-rent-data-consolidated.csv', 'rU') as readfile:\n",
    "        reader = csv.DictReader(readfile, dialect=csv.excel)\n",
    "        for row in reader:\n",
    "            key = '%s-%s' % (row['Metro'], row['State'])\n",
    "            if data_together.get(key) is None:\n",
    "                data_together[key] = {'state': row['State'],'3BR2014': row['2014 AVG Median Rent'],'3BR2015': row['2015 AVG Median Rent'],'3BR2016': row['2016 AVG Median Rent']}\n",
    "except OSError:\n",
    "    print (\"error getting input file\")\n",
    "finally:\n",
    "    readfile.close()\n",
    "\n",
    "# Next add in the data from 2BR houses – metro area names are formatted the same way for both of these data sets,\n",
    "# because they're both from Zillow\n",
    "try:\n",
    "    with open('2BR-median-rent-data-consolidated.csv', 'rU') as readfile:\n",
    "        reader = csv.DictReader(readfile, dialect=csv.excel)\n",
    "        for row in reader:\n",
    "            # Check if the given metro area for the given state is in `data_together` already. If not, add it.\n",
    "            key = '%s-%s' % (row['Metro'], row['State'])\n",
    "            if data_together.get(key) is None:\n",
    "                data_together[key] = {'state': row['State'],'2BR2014': row['2014 AVG Median Rent'],'2BR2015': row['2015 AVG Median Rent'],'2BR2016': row['2016 AVG Median Rent']}\n",
    "            else:\n",
    "                data_together[key].update({'2BR2014': row['2014 AVG Median Rent'],'2BR2015': row['2015 AVG Median Rent'],'2BR2016': row['2016 AVG Median Rent']})\n",
    "except OSError:\n",
    "    print (\"error getting input file\")\n",
    "finally:\n",
    "    readfile.close()\n",
    "\n",
    "# Now, open the data from the census on authorized construction permits for new housing to add it in\n",
    "try:\n",
    "    with open('private-units-authorized-consolidated.csv', 'rU') as readfile:\n",
    "        reader = csv.DictReader(readfile, dialect=csv.excel)\n",
    "        for row in reader:\n",
    "            # look at every metro area we already have stored from the Zillow data. If the metro area name we have from\n",
    "            # the Zillow data is also within the metro area name from the census data, add the census data to it.\n",
    "            for key in data_together.keys():\n",
    "                metro = key.split('-')[0]\n",
    "                state = key.split('-')[1]\n",
    "                if row['Metro'].lower().find(metro) != -1 and row['Metro'].split(',')[1].lower().find(state) != -1:\n",
    "                    data_together[key].update({'Census_Metro': row['Metro']})\n",
    "                    for col in row.keys():\n",
    "                        if col != 'Metro':\n",
    "                            data_together[key][col] = row[col]\n",
    "                    break\n",
    "except OSError:\n",
    "    print (\"error getting input file\")\n",
    "finally:\n",
    "    readfile.close()\n",
    "\n",
    "# Write the combined Zillow/Census data to a new file that we can now look at in Google Sheets or Excel\n",
    "with open('authorized-rent-consolidated.csv', 'w') as writefile:\n",
    "    fieldnames = ['2014 3 and 4 Units', '2016 3 and 4 Units', '3BR2014', '2BR2015', '2016 Units Authorized', '2014 2 Units', '2016 2 Units', '2015 2 Units', '2015 Units Authorized', '2015 3 and 4 Units', '2014 Units Authorized', '3BR2016', 'Census_Metro', '3BR2015', 'state', '2BR2014', '2BR2016']\n",
    "    writer = csv.DictWriter(writefile, fieldnames=['2014 3 and 4 Units', '2016 3 and 4 Units', '3BR2014', '2BR2015', '2016 Units Authorized', '2014 2 Units', '2016 2 Units', '2015 2 Units', '2015 Units Authorized', '2015 3 and 4 Units', '2014 Units Authorized', '3BR2016', 'Census_Metro', '3BR2015', 'state', 'metro', '2BR2014', '2BR2016'])\n",
    "    writer.writeheader()\n",
    "    for key in data_together.keys():\n",
    "        row = {}\n",
    "        row['metro'] = key.split('-')[0]\n",
    "        for field in fieldnames:\n",
    "            row[field] = data_together[key].get(field, '')\n",
    "        writer.writerow(row)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding in the dataset on authorized construction, I found another data set from the ACS that has yearly housing statistics for metro areas across the U.S. This contains information on vacancy rates within a metro area, what kind of housing units are in a metro area (i.e. if there are apartment buildings or standalone houses, etc.), what the estimated value of housing is, and a lot more. Combined this using the folloiwng code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "try:\n",
    "    with open('/Users/Matt/Documents/sunshine-b/ACS_16_1YR_CP04_with_ann.csv', 'rU') as readfile:\n",
    "        reader = csv.DictReader(readfile, dialect=csv.excel)\n",
    "        for row in reader:\n",
    "            for key in all_data.keys():\n",
    "                metro = key.split('-')[0]\n",
    "                state = key.split('-')[1]\n",
    "                if row['Geography'].lower().find(metro) != -1 and row['Geography'].split(',')[1].lower().find(state) != -1:\n",
    "                    all_data[key].update(row)\n",
    "                    break\n",
    "except OSError:\n",
    "    print (\"error getting input file\")\n",
    "finally:\n",
    "    readfile.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in all of the data from the ACS survey made the number of data points per metro area untenable. So, I decided to build two different data sets from all of this. \n",
    "\n",
    "### Data Set 1: Percentages Only\n",
    "The first one just kept all data on metro areas that was percentage-based – this means rather than having the \"number of all newly authorized housing units\", converting that into \"the number of newly authorized units as a percentage of the total existing housing units\". It also means keeping the data point on \"vacancy rate\" for a metro area, but not the total number of vacant units. While total values would be helpful data points for analyzing different trends in big vs. small metro areas, this seemed like a useful starting point for looking at the huge number of data points.\n",
    "\n",
    "### Data Set 2: Statistically Significant Changes\n",
    "One cool thing about the ACS data is that it had data points which marked whether the change in data points from year to year were statistically significant or not. What this means: if, say, the percentage of rentors paying more than 35% of their income to rent grew by 1%, a data point would be marked saying that there was a significant change from 2015 to 2016 in that data point. If it changed by, say, 0.01%, the data point would say that there was no statistically significant change. This kind of True/False data point would be useful to analyze when looking at trends in cities from 2014 to 2016.\n",
    "\n",
    "These data sets were edited/aggregated in Excel rather than by code."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
